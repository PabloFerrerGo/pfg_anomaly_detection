{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVw6WIjiT3L5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from numpy import expand_dims\n",
        "from pytorch_lightning import Trainer\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from keras.utils import load_img, img_to_array\n",
        "from anomalib.models import get_model\n",
        "from anomalib.models.padim.lightning_model import Padim\n",
        "from anomalib.config import get_configurable_parameters\n",
        "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
        "from anomalib.data.folder import Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def img_resize(path, foldertype, newfolder):\n",
        "    imgs = os.listdir(path)\n",
        "    for img in imgs:\n",
        "        img_arr = np.array(Image.open(path+'/'+img)) # (288, 352, 3)  \n",
        "        img_new = cv2.resize(img_arr, (288,288))\n",
        "        im = Image.fromarray(img_new)\n",
        "        im.save(f'./data/{newfolder}/{foldertype}/{img}')\n",
        "\n",
        "def resize_img_pipe(oldfolder, newfolder):\n",
        "    os.mkdir(f'./data/{newfolder}')\n",
        "    os.mkdir(f'./data/{newfolder}/abnormal')\n",
        "    os.mkdir(f'./data/{newfolder}/normal')\n",
        "\n",
        "    img_resize(f'./data/{oldfolder}/normal/','normal',newfolder)\n",
        "    img_resize(f'./data/{oldfolder}/abnormal/','abnormal', newfolder)\n",
        "\n",
        "def image_augmenter(path, folder, n, newfolder):\n",
        "    img = img_to_array(load_img(path))\n",
        "    data = expand_dims(img, 0)\n",
        "    datagen = ImageDataGenerator(#rotation_range=40,\n",
        "                                    width_shift_range=0.2, \n",
        "                                    #featurewise_center=True,\n",
        "                                    #featurewise_std_normalization=True,\n",
        "                                    height_shift_range=0.2, \n",
        "                                    #shear_range=0.2, \n",
        "                                    #zoom_range=0.2,\n",
        "                                    #rotation_range=90,\n",
        "                                    brightness_range=[0.4,1.3],\n",
        "                                    horizontal_flip=True,\n",
        "                                    #zca_whitening=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "    count = 0                                \n",
        "    for batch in datagen.flow(data, batch_size=1, save_prefix='orange', save_to_dir=f'./data/{newfolder}/{folder}',save_format='jpg'):\n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break\n",
        "     \n",
        "def gen_img_pipe(oldfolder, newfolder, n, generate):\n",
        "    resize_img_pipe(oldfolder, newfolder)\n",
        "    if generate:\n",
        "        normal = os.listdir(f'./data/{newfolder}/normal')\n",
        "        abnormal =  os.listdir(f'./data/{newfolder}/abnormal')\n",
        "        for end in normal:\n",
        "            image_augmenter(f'./data/{newfolder}/normal/{end}','normal', n, newfolder)\n",
        "        for end in abnormal:\n",
        "            image_augmenter(f'./data/{newfolder}/abnormal/{end}', 'abnormal', n, newfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "gen_img_pipe('naranjas_pynq_0','naranjas_pynq_2_crop_augmentation', 10, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d6mYLAOfT3MA"
      },
      "outputs": [],
      "source": [
        "def anomaset(model):\n",
        "    CONFIG_PATH = f\"./anomalib/models/{model}/custom.yaml\"\n",
        "    # pass the config file to model, callbacks and datamodule\n",
        "    config = get_configurable_parameters(config_path=CONFIG_PATH)\n",
        "    \n",
        "    #config[\"dataset\"][\"name\"] = \"small_18\" \n",
        "    #config[\"model\"][\"backbone\"] = \"resnet18\"  #resnet18, wide_resnet50_2, cait_m48_448, deit_base_distilled_patch16_384\n",
        "    datamodule = Folder(\n",
        "        root=\"./data/naranjas_pynq_2_crop_augmentation\",\n",
        "        image_size=288,\n",
        "        #task='classification',\n",
        "        seed=42)\n",
        "\n",
        "    datamodule.setup()\n",
        "    #model = Padim(input_size=[288, 288], backbone=\"wide_resnet50_2\", layers=['layer1','layer2','layer3'],pre_trained=True)\n",
        "    model = get_model(config) # (288, 352)\n",
        "    callbacks = get_callbacks(config)\n",
        "\n",
        "    return datamodule, model, callbacks, config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jO_-QX5RT3MB"
      },
      "outputs": [],
      "source": [
        "def anomatrain(datamodule, model, callbacks, config):\n",
        "    # start training\n",
        "    trainer = Trainer(**config.trainer, callbacks=callbacks)\n",
        "    trainer.fit(model=model, datamodule=datamodule)\n",
        "    # load best model from checkpoint before evaluating\n",
        "    load_model_callback = LoadModelCallback(weights_path=trainer.checkpoint_callback.best_model_path)\n",
        "    trainer.callbacks.insert(0, load_model_callback)\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O1rlm5N7T3MC"
      },
      "outputs": [],
      "source": [
        "def anomatest(trainer, model, datamodule):\n",
        "    trainer.test(model=model, datamodule=datamodule)\n",
        "    pixAUC = round(float(trainer.logged_metrics['image_F1Score']),4)\n",
        "    imgAUC = round(float(trainer.logged_metrics['image_AUROC']),4)\n",
        "\n",
        "    return pixAUC, imgAUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ngFfKB-nT3MD"
      },
      "outputs": [],
      "source": [
        "def anomastudy(model):\n",
        "    datamodule, model, callbacks, config = anomaset(model)\n",
        "\n",
        "    trainer = anomatrain(datamodule, model, callbacks, config)\n",
        "    \n",
        "    pixAUC, imgAUC = anomatest(trainer, model, datamodule)\n",
        "\n",
        "    return pixAUC, imgAUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Kg09lio1T3ME"
      },
      "outputs": [],
      "source": [
        "def anomaresults(models):\n",
        "    pix, img = {}, {}\n",
        "\n",
        "    for model in models:\n",
        "\n",
        "        pixAUC, imgAUC = anomastudy(model)\n",
        "\n",
        "        pix[model], img[model] = pixAUC, imgAUC\n",
        "\n",
        "    data_pix = pd.DataFrame.from_dict(pix, orient='index')\n",
        "    data_img = pd.DataFrame.from_dict(img, orient='index')\n",
        "    \n",
        "    return data_pix, data_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvlHs9TYT3MF",
        "outputId": "b10b552a-1303-4b30-ac8b-7d0798f8967a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Pablo\\anomalib\\anomalib\\config\\config.py:147: UserWarning: The seed value is now fixed to 0. Up to v0.3.7, the seed was not fixed when the seed value was set to 0. If you want to use the random seed, please select `None` for the seed value (`null` in the YAML file) or remove the `seed` key from the YAML file.\n",
            "  warn(\n",
            "C:\\Users\\Pablo\\anomalib\\anomalib\\config\\config.py:175: UserWarning: config.project.unique_dir is set to False. This does not ensure that your results will be written in an empty directory and you may overwrite files.\n",
            "  warn(\n",
            "Transform configs has not been provided. Images will be normalized using ImageNet statistics.\n",
            "Transform configs has not been provided. Images will be normalized using ImageNet statistics.\n",
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "C:\\Users\\Pablo\\anomalib\\anomalib\\utils\\callbacks\\__init__.py:141: UserWarning: Export option: None not found. Defaulting to no model export\n",
            "  warnings.warn(f\"Export option: {config.optimization.export_mode} not found. Defaulting to no model export\")\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:611: UserWarning: Checkpoint directory C:\\Users\\Pablo\\Desktop\\Ciencia de Datos\\Cuarto\\1 IOT\\Proyecto\\PROYECTO\\results\\patchcore\\small_50_patch\\run\\weights exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:183: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
            "  rank_zero_warn(\n",
            "\n",
            "  | Name                  | Type                     | Params\n",
            "-------------------------------------------------------------------\n",
            "0 | image_threshold       | AnomalyScoreThreshold    | 0     \n",
            "1 | pixel_threshold       | AnomalyScoreThreshold    | 0     \n",
            "2 | model                 | PatchcoreModel           | 24.9 M\n",
            "3 | image_metrics         | AnomalibMetricCollection | 0     \n",
            "4 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
            "5 | normalization_metrics | MinMax                   | 0     \n",
            "-------------------------------------------------------------------\n",
            "24.9 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.9 M    Total params\n",
            "99.450    Total estimated model params size (MB)\n",
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1933: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:  64%|██████▍   | 9/14 [01:40<00:55, 11.18s/it, loss=nan, v_num=1]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: ''",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpatchcore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m#,'draem','dfm', 'cflow', 'stfpm', 'ganomaly', 'dfkde', 'patchcore']\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data_f1, data_img \u001b[39m=\u001b[39m anomaresults(models)\n",
            "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36manomaresults\u001b[1;34m(models)\u001b[0m\n\u001b[0;32m      2\u001b[0m pix, img \u001b[39m=\u001b[39m {}, {}\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m----> 6\u001b[0m     pixAUC, imgAUC \u001b[39m=\u001b[39m anomastudy(model)\n\u001b[0;32m      8\u001b[0m     pix[model], img[model] \u001b[39m=\u001b[39m pixAUC, imgAUC\n\u001b[0;32m     10\u001b[0m data_pix \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(pix, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36manomastudy\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m datamodule, model, callbacks, config \u001b[39m=\u001b[39m anomaset(model)\n\u001b[0;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m anomatrain(datamodule, model, callbacks, config)\n\u001b[1;32m----> 6\u001b[0m pixAUC, imgAUC \u001b[39m=\u001b[39m anomatest(trainer, model, datamodule)\n\u001b[0;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m pixAUC, imgAUC\n",
            "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36manomatest\u001b[1;34m(trainer, model, datamodule)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manomatest\u001b[39m(trainer, model, datamodule):\n\u001b[1;32m----> 2\u001b[0m     trainer\u001b[39m.\u001b[39;49mtest(model\u001b[39m=\u001b[39;49mmodel, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n\u001b[0;32m      3\u001b[0m     pixAUC \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\u001b[39mfloat\u001b[39m(trainer\u001b[39m.\u001b[39mlogged_metrics[\u001b[39m'\u001b[39m\u001b[39mimage_F1Score\u001b[39m\u001b[39m'\u001b[39m]),\u001b[39m4\u001b[39m)\n\u001b[0;32m      4\u001b[0m     imgAUC \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\u001b[39mfloat\u001b[39m(trainer\u001b[39m.\u001b[39mlogged_metrics[\u001b[39m'\u001b[39m\u001b[39mimage_AUROC\u001b[39m\u001b[39m'\u001b[39m]),\u001b[39m4\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:938\u001b[0m, in \u001b[0;36mTrainer.test\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mPerform one evaluation epoch over the test set.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mIt's separated from fit to make sure you never run on your test set until you want to.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[39m    The length of the list corresponds to the number of test dataloaders used.\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    937\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[1;32m--> 938\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule)\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    722\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 723\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    724\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:985\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    987\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1174\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39msetup_environment()\n\u001b[0;32m   1172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__setup_profiler()\n\u001b[1;32m-> 1174\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_setup_hook()  \u001b[39m# allow user to setup lightning_module in accelerator environment\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39m# check if we should delay restoring checkpoint till later\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1493\u001b[0m, in \u001b[0;36mTrainer._call_setup_hook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39msetup(stage\u001b[39m=\u001b[39mfn)\n\u001b[1;32m-> 1493\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_callback_hooks(\u001b[39m\"\u001b[39;49m\u001b[39msetup\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage\u001b[39m=\u001b[39;49mfn)\n\u001b[0;32m   1494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39msetup\u001b[39m\u001b[39m\"\u001b[39m, stage\u001b[39m=\u001b[39mfn)\n\u001b[0;32m   1496\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mpost_setup\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1636\u001b[0m, in \u001b[0;36mTrainer._call_callback_hooks\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1634\u001b[0m         \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[0;32m   1635\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1636\u001b[0m                 fn(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1638\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[0;32m   1639\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1640\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32m~\\anomalib\\anomalib\\utils\\callbacks\\model_loader.py:32\u001b[0m, in \u001b[0;36mLoadModelCallback.setup\u001b[1;34m(self, trainer, pl_module, stage)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m\"\"\"Call when inference begins.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39mLoads the model weights from ``weights_path`` into the PyTorch module.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLoading the model from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_path)\n\u001b[1;32m---> 32\u001b[0m pl_module\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights_path, map_location\u001b[39m=\u001b[39;49mpl_module\u001b[39m.\u001b[39;49mdevice)[\u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[1;32mc:\\Users\\Pablo\\anaconda3\\envs\\anomalib_env\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ],
      "source": [
        "models = ['patchcore']#,'draem','dfm', 'cflow', 'stfpm', 'ganomaly', 'dfkde', 'patchcore']\n",
        "\n",
        "data_f1, data_img = anomaresults(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model = torchvision.models.resnet101()\n",
        "#for name, layer in model.named_modules():\n",
        "#    print(name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('anomalib_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b995a6c14cfff16ab868bd1edfb3534d81d6a8caffd4b9b8fc69acf7bae847c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
