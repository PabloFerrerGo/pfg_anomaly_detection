{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVw6WIjiT3L5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import timeit\n",
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "import timm\n",
        "\n",
        "from numpy import expand_dims\n",
        "from pytorch_lightning import Trainer\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "from keras.utils import load_img, img_to_array\n",
        "from anomalib.models import get_model\n",
        "from anomalib.models.padim.lightning_model import Padim\n",
        "from anomalib.config import get_configurable_parameters\n",
        "from anomalib.utils.callbacks import LoadModelCallback, get_callbacks\n",
        "from anomalib.data.folder import Folder\n",
        "from anomalib.data.mvtec import MVTec\n",
        "\n",
        "from anomalib.models.fastflow.lightning_model import Fastflow\n",
        "from anomalib.models.dfm.lightning_model import Dfm\n",
        "from anomalib.models.patchcore.lightning_model import Patchcore\n",
        "from anomalib.models.cflow.lightning_model import Cflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def anomaset(model, tuned_model):\n",
        "    CONFIG_PATH = f\"./anomalib/models/{model}/config.yaml\"\n",
        "\n",
        "    config = get_configurable_parameters(config_path=CONFIG_PATH)\n",
        "\n",
        "    datamodule = MVTec(\n",
        "        root=\"../data/mvtec_anomaly_detection\",\n",
        "        category='capsule',\n",
        "        image_size=256,\n",
        "        train_batch_size=32,\n",
        "        test_batch_size=32,\n",
        "        num_workers=8,\n",
        "        task =\"segmentation\",\n",
        "        seed = 42)\n",
        "\n",
        "    datamodule.setup()\n",
        "    model = tuned_model\n",
        "\n",
        "    callbacks = get_callbacks(config)\n",
        "\n",
        "    return datamodule, model, callbacks, config\n",
        "\n",
        "def anomatrain(datamodule, model, callbacks, config):\n",
        "    trainer = Trainer(**config.trainer, callbacks=callbacks)\n",
        "    trainer.fit(model=model, datamodule=datamodule)\n",
        "    load_model_callback = LoadModelCallback(weights_path=trainer.checkpoint_callback.best_model_path)\n",
        "    trainer.callbacks.insert(0, load_model_callback)\n",
        "    return trainer\n",
        "\n",
        "def anomatest(trainer, model, datamodule):\n",
        "    trainer.test(model=model, datamodule=datamodule)\n",
        "    df = trainer.logged_metrics\n",
        "    return  df\n",
        "\n",
        "def anomastudy(model):\n",
        "    datamodule, model, callbacks, config = anomaset(model)\n",
        "    trainer = anomatrain(datamodule, model, callbacks, config)\n",
        "    metrics = anomatest(trainer, model, datamodule)\n",
        "    return metrics\n",
        "\n",
        "def anomaresults(models):\n",
        "    for model in models:\n",
        "        metrics = anomastudy(model)\n",
        "    return metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def img_resize(path, foldertype, newfolder):\n",
        "    imgs = os.listdir(path)\n",
        "    for img in imgs:\n",
        "        img_arr = np.array(Image.open(path+'/'+img)) # (288, 352, 3)  \n",
        "        img_new = cv2.resize(img_arr, (288,288))\n",
        "        im = Image.fromarray(img_new)\n",
        "        im.save(f'./data/{newfolder}/{foldertype}/{img}')\n",
        "\n",
        "def resize_img_pipe(oldfolder, newfolder):\n",
        "    os.mkdir(f'./data/{newfolder}')\n",
        "    os.mkdir(f'./data/{newfolder}/abnormal')\n",
        "    os.mkdir(f'./data/{newfolder}/normal')\n",
        "\n",
        "    img_resize(f'./data/{oldfolder}/normal/','normal',newfolder)\n",
        "    img_resize(f'./data/{oldfolder}/abnormal/','abnormal', newfolder)\n",
        "\n",
        "def image_augmenter(path, folder, n, newfolder):\n",
        "    img = img_to_array(load_img(path))\n",
        "    data = expand_dims(img, 0)\n",
        "    datagen = ImageDataGenerator(#rotation_range=40,\n",
        "                                    width_shift_range=0.2, \n",
        "                                    #featurewise_center=True,\n",
        "                                    #featurewise_std_normalization=True,\n",
        "                                    height_shift_range=0.2, \n",
        "                                    #shear_range=0.2, \n",
        "                                    #zoom_range=0.2,\n",
        "                                    #rotation_range=90,\n",
        "                                    brightness_range=[0.4,1.3],\n",
        "                                    horizontal_flip=True,\n",
        "                                    #zca_whitening=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    fill_mode='nearest')\n",
        "    count = 0                                \n",
        "    for batch in datagen.flow(data, batch_size=1, save_prefix='orange', save_to_dir=f'./data/{newfolder}/{folder}',save_format='jpg'):\n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break\n",
        "     \n",
        "def gen_img_pipe(oldfolder, newfolder, n, generate):\n",
        "    resize_img_pipe(oldfolder, newfolder)\n",
        "    if generate:\n",
        "        normal = os.listdir(f'./data/{newfolder}/normal')\n",
        "        abnormal =  os.listdir(f'./data/{newfolder}/abnormal')\n",
        "        for end in normal:\n",
        "            image_augmenter(f'./data/{newfolder}/normal/{end}','normal', n, newfolder)\n",
        "        for end in abnormal:\n",
        "            image_augmenter(f'./data/{newfolder}/abnormal/{end}', 'abnormal', n, newfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gen_img_pipe('naranjas_pynq_0','naranjas_pynq_2_crop_augmentation', 10, True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names = timm.list_models()\n",
        "model_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = timm.create_model('efficientnet_l2', pretrained=True)\n",
        "#print(model_names)\n",
        "layer_names = [name for name, _ in model.named_children()]\n",
        "print(layer_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = ['padim']#,'draem','dfm', 'cflow', 'stfpm', 'ganomaly', 'dfkde', 'patchcore']\n",
        "# categories = ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
        "new_model = Dfm(backbone='efficientnet_l2',layer='conv_head')\n",
        "\n",
        "metrics = anomaresults(models, new_model)\n",
        "metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(Dfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = ['dfm']\n",
        "tuned_model = Dfm(backbone='efficientnet_l2',layer='conv_head',score_type='fre', pooling_kernel_size=4)\n",
        "metrics = anomaresults(models, tuned_model)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_model_1 = Dfm(backbone='efficientnet_l2',layer='conv_head',score_type='nll', pooling_kernel_size=2)\n",
        "tuned_model_2 = Patchcore(input_size=[256, 256], backbone=\"resnet18\", layers=['layer2','layer3'],coreset_sampling_ratio=0.3, num_neighbors=18)\n",
        "tuned_model_3 = Cflow(input_size=[256, 256], backbone=\"resnet18\", layers=['layer2','layer3','layer4'])\n",
        "tuned_model_4 = Fastflow(input_size=[256,256], backbone='resnet18',weight_decay=0.0001)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " # WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hpo_yaml_file = \"\"\"\n",
        "observation_budget: 10\n",
        "method: bayes\n",
        "metric:\n",
        "  name: pixel_AUPR\n",
        "  goal: maximize\n",
        "parameters:\n",
        "  model:\n",
        "    pooling_kernel_size:\n",
        "      values: [2,4]\n",
        "\"\"\"\n",
        "\n",
        "with open(\"C:/Users/Pablo/Desktop/hpo.yaml\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.writelines(hpo_yaml_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python \"C:/Users/Pablo/anomalib/tools/hpo/sweep.py\" --model dfm --model_config \"C:/Users/Pablo/anomalib/anomalib/models/dfm/config.yaml\" --sweep_config \"C:/Users/Pablo/Desktop/hpo.yaml\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('anomalib_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b995a6c14cfff16ab868bd1edfb3534d81d6a8caffd4b9b8fc69acf7bae847c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
