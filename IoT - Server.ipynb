{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, json, ast\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from anomalib.models.padim.lightning_model import PadimLightning\n",
    "from anomalib.data.inference import InferenceDataset\n",
    "from anomalib.pre_processing.transforms import Denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(root):\n",
    "    checkpoint = os.listdir(root)[0]\n",
    "    print(checkpoint)\n",
    "    model = PadimLightning.load_from_checkpoint(f\"{root}/{checkpoint}\")\n",
    "    trainer = Trainer(progress_bar_refresh_rate=0)\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_photo(host, port, topic):\n",
    "\n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        print('Connected to PHOTO '+str(rc))\n",
    "        client.subscribe(topic)\n",
    "        \n",
    "    def on_message(client, userdata, msg):\n",
    "        data = json.loads(msg.payload.decode(\"utf8\"))\n",
    "\n",
    "        image = str(list(data.values())[0])\n",
    "        c = int(list(data.keys())[0])\n",
    "        timestamp = str(list(data.values())[1])\n",
    "\n",
    "        with open(f'./data/timestamp.txt','w') as f:\n",
    "            f.write(timestamp)\n",
    "        print('timestamp written')\n",
    "\n",
    "        with open(f'./data/image_{c}.txt','w') as f:\n",
    "            f.write(image)\n",
    "        print('image written')\n",
    "        \n",
    "        if c == 2:\n",
    "            client.disconnect()\n",
    "\n",
    "    client = mqtt.Client()\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "\n",
    "    client.connect(host, port, keepalive=180)\n",
    "    client.loop_forever()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pub_results(model, trainer,image, host, port, topic):\n",
    "    dataset = DataLoader(InferenceDataset(f\"./data/webcam_images/{image}.png\", image_size=tuple([288,288])))\n",
    "    output = trainer.predict(model=model, dataloaders=dataset)[0]\n",
    "    pred_label = str(int(output['pred_labels'].tolist()[0]))\n",
    "\n",
    "    client = mqtt.Client()\n",
    "    client.connect(host, port, keepalive=180)\n",
    "    client.publish(topic, pred_label)\n",
    "    #print('RESULTS published')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48750b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_img():\n",
    "    image = np.zeros((288,288,3)) \n",
    "    timestamp = open(f'./data/timestamp.txt', \"r\").read()\n",
    "    for channel in range(3):\n",
    "        f = open(f'./data/image_{channel}.txt', \"r\")\n",
    "        output = f.read()\n",
    "        msg_list = ast.literal_eval(output)\n",
    "        msg_ndar = np.asarray(msg_list)\n",
    "        image[:,:,channel] = msg_ndar\n",
    "    cv2.imwrite(f'./data/webcam_images/webcam_{timestamp}.png', image)\n",
    "    return image, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "port = 1883\n",
    "model, trainer = load_model('./results/padim/big_50/run/weights/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = DataLoader(InferenceDataset(f\"./que.jpg\", image_size=tuple([288,288])))\n",
    "output = trainer.predict(model=model, dataloaders=dataset)[0]\n",
    "pred_label = str(int(output['pred_labels'].tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eec733",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = \"192.168.137.70\"\n",
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a654b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    sub_photo(ip, port, 'photo')\n",
    "    print(\"Foto recibida\")\n",
    "    \n",
    "    img, timestamp = text_to_img()\n",
    "    \n",
    "    #print(\"Publicando resultados\")\n",
    "    output = pub_results(model, trainer,f'webcam_{timestamp}', ip, port, 'results')\n",
    "    outputs[f'webcam_{timestamp}'] = output\n",
    "    print(\"Resultados publicados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path):\n",
    "    output = outputs[path]\n",
    "    image = Denormalize()(output[\"image\"][0])\n",
    "    #print(f\"Image Shape: {image.shape}\\n Min Pixel: {image.min()} \\n Max Pixel: {image.max()}\")\n",
    "    #plt.imshow(image)\n",
    "    return image\n",
    "\n",
    "def show_anomaly_map(path):\n",
    "    output = outputs[path]\n",
    "    anomaly_map = output[\"anomaly_maps\"][0].cpu().numpy().squeeze()\n",
    "    #plt.imshow(anomaly_map)\n",
    "    return anomaly_map\n",
    "    \n",
    "def show_pred_maks(path):\n",
    "    output = outputs[path]\n",
    "    pred_masks = output[\"pred_masks\"][0].squeeze().cpu().numpy()\n",
    "    #plt.imshow(pred_masks)\n",
    "    return pred_masks\n",
    "\n",
    "def show_results(path):\n",
    "    image = show_image(path)\n",
    "    anomaly_map = show_anomaly_map(path)\n",
    "    pred_masks = show_pred_maks(path)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax2.imshow(anomaly_map)\n",
    "    ax3.imshow(pred_masks)\n",
    "\n",
    "    ax1.set_title('Image')\n",
    "    ax2.set_title('Anomaly map')\n",
    "    ax3.set_title('Predicted masks')\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anomalib_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b995a6c14cfff16ab868bd1edfb3534d81d6a8caffd4b9b8fc69acf7bae847c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
